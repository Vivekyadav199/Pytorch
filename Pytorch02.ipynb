{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Tensor\n",
    "\n",
    "Why random tensors?\n",
    "\n",
    "Random tensors are important becouse the way many neural networks learn is that they start with tensors full of random numbers and the adjust those Random numbers to better represent the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " start with random numbers -> look at the data -> update the random numbers ->Look at the data -> update random numbers\n",
    "Torch random Tesnors- https://pytorch.org/docs/stable/generated/torch.rand.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch    \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4486, 0.5919, 0.1738, 0.2224],\n",
       "        [0.8688, 0.2222, 0.8358, 0.9663],\n",
       "        [0.5563, 0.1340, 0.3377, 0.9547]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(3,4)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 224, 224]), 3)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_image_size_tensor = torch.rand(3, 224, 224)#height , width , colour chnals(R<G<B))\n",
    "random_image_size_tensor.shape, random_image_size_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1+cu124\n"
     ]
    }
   ],
   "source": [
    "print(torch. __version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.], device='cuda:0')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var1 = torch.FloatTensor([1.0,2.0,3.0]).cuda()\n",
    "var1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var1.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zeros and Ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a tensor of zeros\n",
    "zero = torch.zeros(size = (3,4))\n",
    "zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero*random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of Ones\n",
    "ones = torch.ones(size = (3,4))\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a range of tensors and Tensors-Like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use torch.range\n",
    "one_to_ten = torch.arange(1,11) \n",
    "one_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  6, 11, 16, 21, 26, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86,\n",
       "        91, 96])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using steps methods\n",
    "one_to_hunderd = torch.arange(start = 1, end = 100, step = 5)\n",
    "one_to_hunderd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating tesnor Like\n",
    "Ten_zeros = torch.zeros_like(one_to_ten) # same shape as one_to_ten\n",
    "Ten_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor datatypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# float 32 tensor \n",
    "float_32_1_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=None,) # defaults to None)\n",
    "float_32_1_tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_1_tensor.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], dtype=torch.float16)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# float 32 tensor \n",
    "float_16_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=torch.float16,)\n",
    "float_16_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], device='cuda:0')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tesnor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=None,\n",
    "                               device = \"cuda\", # what device is your tensor on (none for cpu)\n",
    "                               requires_grad=False) # whether or not to track gradients with this tensor opertaion(for now)\n",
    "                               \n",
    "\n",
    "float_32_tesnor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### tensor dataype\n",
    "**note:** tensor datatypes is one of the 3 big errors you'll run into with pytorch & deep learning\n",
    "\n",
    "**1.** tensor not right datatype\n",
    "\n",
    "**2.** tesnor not right shape\n",
    "\n",
    "**3.** tensor not on the right device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how to change the datatype\n",
    "float_16_tensor = float_32_tesnor.type(torch.float16)\n",
    "float_16_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### link for the pytorch datatype documentation\n",
    "https://pytorch.org/docs/stable/tensors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.], device='cuda:0')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#what happens\n",
    "float_16_tensor * float_32_tesnor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9], device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_tensor = torch.tensor([3, 6, 9], dtype = torch.int32,\n",
    "                             device =\"cuda\",\n",
    "                             requires_grad = False)\n",
    "int_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.], device='cuda:0')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "float_32_tesnor*int_32_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Getting the information from tensor \n",
    "\n",
    "**1.** tensor not right datatype - to do go get datatype from a tensor, can use `tesnor.dtype`\n",
    "\n",
    "**2.** tesnor not right shape - to get shape from a tensor, can use `tensor.shape`\n",
    "\n",
    "**3.** tensor not on the right device - to get deivr from a tensor, can use `tensor.device`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3906, 0.3526, 0.5042, 0.1629],\n",
       "        [0.3441, 0.0301, 0.6208, 0.7103],\n",
       "        [0.5688, 0.4651, 0.7688, 0.9069]], device='cuda:0')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a tensor \n",
    "some_tensor = torch.rand((3,4),dtype = torch.float32, device = \"cuda\", requires_grad = False)\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datatype of some_tensor: torch.float32\n",
      "Shape of some_tensor: torch.Size([3, 4])\n",
      "Device of some_tensor: cuda:0\n"
     ]
    }
   ],
   "source": [
    "#find out the details about some_tensor\n",
    "print(f\"Datatype of some_tensor: {some_tensor.dtype}\")\n",
    "print(f\"Shape of some_tensor: {some_tensor.shape}\")\n",
    "print(f\"Device of some_tensor: {some_tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5859, 0.8477, 0.2518, 0.5253],\n",
       "        [0.4239, 0.2930, 0.7918, 0.2411],\n",
       "        [0.0368, 0.2740, 0.6924, 0.4087]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a tensor1\n",
    "some_tensor1 = torch.rand(3,4)\n",
    "some_tensor1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datatype of some_tensor: torch.float32\n",
      "Shape of some_tensor: torch.Size([3, 4])\n",
      "Device of some_tensor: cpu\n"
     ]
    }
   ],
   "source": [
    "#find out the details about some_tensor\n",
    "print(f\"Datatype of some_tensor: {some_tensor1.dtype}\")\n",
    "print(f\"Shape of some_tensor: {some_tensor1.shape}\")\n",
    "print(f\"Device of some_tensor: {some_tensor1.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manipulating Tensor (tensor operation)\n",
    "\n",
    "Tensor opertations includes:\n",
    "\n",
    "**1.** Addition\n",
    "\n",
    "**2.** Subtration\n",
    "\n",
    "**3.** Multiplication(element - wise)\n",
    "\n",
    "**4.** Division \n",
    "\n",
    "**5.** Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a tensor and add 10 to it\n",
    "tensor = torch.tensor([1,2,3])\n",
    "tensor +10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#multiplication tenor with 10\n",
    "tensor*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#subtration 10\n",
    "tensor -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try out Pytorch in_built function\n",
    "# torch.add\n",
    "torch.mul(tensor, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matric multiplication\n",
    "\n",
    "Tow main ways of performing multiplication in nerural network and deeplearning \n",
    "\n",
    "**1.** Element- wise multiplication\n",
    "\n",
    "**2.** Matrix multiplication (dot product )\n",
    "\n",
    "`There are tow main rules that performing matrix multiplication need to satisy:`\n",
    "\n",
    "**1.** The `inner dimension` must match:\n",
    "* `(3,2) @ (3,2)` won't work\n",
    "* `(2,3) @ (3,2)` will work\n",
    "* `(3,2) @ (2,3)` will work\n",
    "* **note** @ represent dot product like matrix multiplication\n",
    "\n",
    "**2.** The resulting matrix has the shape of `outer dimensions`\n",
    "* `(2,3) @ (3,2)` -> `(2,2)`\n",
    "* `(3,2) @ (2,3)` -> `(3,3)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "Equals: tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "#Element Wise Multiplication\n",
    "print( tensor,\"*\",tensor)\n",
    "print(f\"Equals: {tensor * tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication \n",
    "torch.matmul(tensor,tensor) #dot product 1*1 + 2*2 + 3*3 = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n",
      "tensor(14)\n"
     ]
    }
   ],
   "source": [
    "# Matrix multiplication by hand\n",
    "%time\n",
    "value = 0\n",
    "for i in range(len(tensor)):\n",
    "  value += tensor[i]*tensor[i]\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "torch.matmul(tensor,tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1019, 0.2977],\n",
       "        [0.2997, 1.3543]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(torch.rand(2,3),torch.rand(3,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use this for your experiments\n",
    "https://matrixmultiplication.xyz/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_A = torch.tensor([[1,2],\n",
    "                          [3,4],\n",
    "                          [5,6]])\n",
    "tensor_B = torch.tensor([[7,10],\n",
    "                          [8,11],\n",
    "                          [9,12]])\n",
    "#torch.mm(tensor_A, tensor_B) # torch.mm is the same as torch.matmul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RuntimeError: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([3, 2]))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_A.shape, tensor_B.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fix our tensor shape issues , we can manipulate the shape of the tensor using a `transpose`\n",
    "\n",
    "A `transpose` switches the axes or dimensions of given tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 7,  8,  9],\n",
      "        [10, 11, 12]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tensor_B.T)\n",
    "tensor_B.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 7, 10],\n",
      "        [ 8, 11],\n",
      "        [ 9, 12]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tensor_B)\n",
    "tensor_B.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### as you can see that the transpose change the dimension of the matrix but not the elements so it will effect the dimensions of the matrix but not the result or the output of the data set\n",
    "`T` represent `transpose`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(tensor_A, tensor_B.T).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### finding the min, max, mean, sum, etc(tensor aggregation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a tensor\n",
    "x = torch.arange(1,100,10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1), tensor(1), tensor(91))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the min\n",
    "torch.min(x), x.min(), x.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RuntimeError `                             Traceback (most recent call last)\n",
    "`Cell In[45], line 1`\n",
    "`----> 1 torch.mean(x)`\n",
    "\n",
    "``RuntimeError: mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(46.), tensor(46.))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(x.type(torch.float32)), x.type(torch.float32).mean()\n",
    "# Find the mean - note: the torch.mean() function requires a tensor of float32 datatype to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(460), tensor(460))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the sum\n",
    "torch.sum(x), x.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Finding the positional min and max**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the positional in tesnor that has the minimum value with argmin() -> returns index position of target tensor where the minimum value occurs\n",
    "x.argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the positional in tesnor that has the maximum value with argmax() -> returns index position of target tensor where the maximum value occurs\n",
    "x.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(91)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Reshaping, Stacking, Squeezing and Unsqueezing tensors**\n",
    "\n",
    "**Reshaping** - `reshapes an input tensor to a defined shape`\n",
    "\n",
    "**View** - `Return a view of an input tensor of certain shape but keep the same memory as the original tensor `\n",
    "\n",
    "**Stacking** - `combine multiple tensor on top of each other (vstack) or side by side(hstack)`*https://pytorch.org/docs/stable/generated/torch.stack.html*\n",
    "\n",
    "   ###**(vstake)** - *https://pytorch.org/docs/stable/generated/torch.vstack.html*\n",
    "\n",
    "   ###**(hstack)** - *https://pytorch.org/docs/stable/generated/torch.hstack.html*\n",
    "\n",
    "**Squeeze** -`remove all` 1 `dimension from a tensor`\n",
    "\n",
    "**Unsqueeze** - `add a` 1 `dimension to a target tensor`\n",
    "\n",
    "**Permute** - `Return a view of the input with dimensions permuted (swapped) in certain way`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1.,10.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add an extra dimension\n",
    "#x_reshaped = x.reshape(1,7)\n",
    "#x_reshaped, x_reshaped.shape\n",
    "#/---------------------------------------------------------------------------\n",
    "#RuntimeError                              Traceback (most recent call last)\n",
    "#Cell In[52], line 2\n",
    "#     1 # add an extra dimension\n",
    "#--> 2 x_reshaped = x.reshape(1,7)\n",
    "#   3 x_reshaped, x_reshaped.shape\n",
    "\n",
    "#RuntimeError: shape '[1, 7]' is invalid for input of size 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped = x.reshape(1,9)\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.],\n",
       "         [2.],\n",
       "         [3.],\n",
       "         [4.],\n",
       "         [5.],\n",
       "         [6.],\n",
       "         [7.],\n",
       "         [8.],\n",
       "         [9.]]),\n",
       " torch.Size([9, 1]))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped = x.reshape(9,1)\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change the view\n",
    "z = x.view(1,9)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
       " tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#changing z changes x(because a view of a tensor shares the same memory as the original input)\n",
    "z[:,0] = 5\n",
    "z, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [5., 2., 3., 4., 5., 6., 7., 8., 9.]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stack tensors on top of each other\n",
    "x_stacked = torch.stack([x,x,x],dim=0)\n",
    "x_stacked "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([[5.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [4.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [7.],\n",
      "        [8.],\n",
      "        [9.]])\n",
      "Previous shape: torch.Size([9, 1])\n",
      "\n",
      "New tensor: tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "\n",
      "New shape: torch.Size([9])\n"
     ]
    }
   ],
   "source": [
    "#squeeze\n",
    "print(f\"Previous tensor: {x_reshaped}\")\n",
    "print(f\"Previous shape: {x_reshaped.shape}\")\n",
    "\n",
    "x_reshaped = x_reshaped.squeeze()\n",
    "print(f\"\\nNew tensor: {x_reshaped}\")\n",
    "print(f\"\\nNew shape: {x_reshaped.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous Target: tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
      "        [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
      "        [5., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
      "Previous shape: torch.Size([3, 9])\n",
      "\n",
      "New Target: tensor([[[5.],\n",
      "         [2.],\n",
      "         [3.],\n",
      "         [4.],\n",
      "         [5.],\n",
      "         [6.],\n",
      "         [7.],\n",
      "         [8.],\n",
      "         [9.]],\n",
      "\n",
      "        [[5.],\n",
      "         [2.],\n",
      "         [3.],\n",
      "         [4.],\n",
      "         [5.],\n",
      "         [6.],\n",
      "         [7.],\n",
      "         [8.],\n",
      "         [9.]],\n",
      "\n",
      "        [[5.],\n",
      "         [2.],\n",
      "         [3.],\n",
      "         [4.],\n",
      "         [5.],\n",
      "         [6.],\n",
      "         [7.],\n",
      "         [8.],\n",
      "         [9.]]])\n",
      "New shape: torch.Size([3, 9, 1])\n"
     ]
    }
   ],
   "source": [
    "# torch.unqueeze() - adds a single dimension to a target tensor at a specified dimension\n",
    "print(f\"Previous Target: {x_stacked}\")\n",
    "print(f\"Previous shape: {x_stacked.shape}\")\n",
    "\n",
    "#add an extra dimension with unsqueeze\n",
    "x_unsqueezed = x_stacked.unsqueeze(dim=2)\n",
    "print(f\"\\nNew Target: {x_unsqueezed}\")\n",
    "print(f\"New shape: {x_unsqueezed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape: torch.Size([224, 224, 3])\n",
      "New shape: torch.Size([224, 3, 224])\n"
     ]
    }
   ],
   "source": [
    "#torch.permute - rearranges the dimensions of a target tensor in a specified order\n",
    "x_original = torch.rand(size=(224,224,3)) # [height, width, colour_channels]\n",
    "\n",
    "# Permute the original tensor to rearrange the axis (or dim) order\n",
    "x_permuted = x_original.permute(0, 2, 1) # shifts axis 0->1, 1->2, 2->0)\n",
    "\n",
    "print(f\"Previous shape: {x_original.shape}\")\n",
    "print(f\"New shape: {x_permuted.shape}\")  # [height, colour_channels, width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.3469e-01, 7.2100e-01, 2.0429e-01],\n",
       "        [7.8787e-01, 6.8404e-01, 8.5688e-01],\n",
       "        [6.9186e-01, 8.5506e-01, 1.6372e-01],\n",
       "        [7.5847e-01, 3.4303e-01, 2.7261e-01],\n",
       "        [5.0040e-01, 5.8201e-01, 4.0344e-01],\n",
       "        [3.2129e-01, 5.9817e-01, 6.4721e-01],\n",
       "        [1.9968e-01, 4.7186e-01, 5.8595e-01],\n",
       "        [3.9441e-01, 5.8991e-01, 3.1996e-01],\n",
       "        [2.2566e-01, 8.9507e-02, 7.4718e-01],\n",
       "        [4.8118e-01, 6.2667e-01, 7.6498e-01],\n",
       "        [4.5287e-01, 6.9337e-01, 6.7011e-01],\n",
       "        [1.4814e-01, 5.8685e-01, 2.0759e-01],\n",
       "        [4.3926e-01, 9.5840e-01, 7.6236e-01],\n",
       "        [3.3729e-01, 5.5950e-01, 7.1816e-01],\n",
       "        [2.7814e-01, 5.3569e-01, 2.4331e-01],\n",
       "        [1.3319e-01, 5.7277e-01, 2.5378e-01],\n",
       "        [1.7519e-01, 5.6313e-01, 5.8220e-01],\n",
       "        [5.2472e-01, 6.3464e-01, 2.0257e-01],\n",
       "        [7.7857e-01, 2.5694e-01, 5.6789e-01],\n",
       "        [1.6685e-01, 8.7140e-01, 2.9835e-01],\n",
       "        [7.6879e-01, 4.9997e-02, 1.0229e-01],\n",
       "        [7.7882e-01, 9.1753e-01, 4.6441e-01],\n",
       "        [7.8799e-01, 4.7806e-01, 2.3590e-01],\n",
       "        [8.4301e-01, 9.9048e-01, 2.4174e-01],\n",
       "        [8.4582e-01, 5.3770e-01, 9.6560e-01],\n",
       "        [8.0146e-01, 8.3506e-01, 6.7664e-01],\n",
       "        [9.6375e-01, 3.3654e-01, 4.4282e-01],\n",
       "        [6.5917e-01, 8.9390e-01, 2.1490e-01],\n",
       "        [4.2010e-01, 1.0108e-01, 9.7045e-01],\n",
       "        [3.3480e-01, 7.5324e-02, 8.0903e-01],\n",
       "        [6.3467e-01, 3.0947e-01, 1.9812e-01],\n",
       "        [9.4508e-01, 1.7328e-01, 8.9054e-02],\n",
       "        [2.7792e-01, 6.4256e-01, 8.8085e-02],\n",
       "        [3.4061e-01, 4.8617e-02, 8.9530e-01],\n",
       "        [5.3984e-01, 1.0854e-01, 3.7302e-01],\n",
       "        [6.8684e-01, 1.5635e-02, 4.2121e-01],\n",
       "        [1.8730e-01, 6.9888e-01, 7.4349e-01],\n",
       "        [5.0188e-01, 1.3326e-01, 1.2266e-01],\n",
       "        [6.9563e-01, 9.7740e-01, 2.7880e-01],\n",
       "        [8.4469e-01, 4.7795e-01, 7.0259e-01],\n",
       "        [3.2819e-01, 8.7311e-01, 1.0539e-02],\n",
       "        [4.5161e-01, 1.5062e-01, 3.1699e-01],\n",
       "        [2.9367e-01, 7.7138e-01, 1.6074e-01],\n",
       "        [6.0324e-02, 4.9320e-01, 3.7131e-01],\n",
       "        [8.0165e-01, 4.6948e-01, 3.5335e-02],\n",
       "        [7.0357e-01, 2.1490e-01, 9.6918e-01],\n",
       "        [4.9540e-01, 4.3527e-01, 5.0788e-01],\n",
       "        [6.5032e-01, 8.1284e-02, 3.2923e-01],\n",
       "        [5.2548e-01, 1.0197e-01, 9.0198e-01],\n",
       "        [9.9898e-01, 5.6814e-01, 2.6948e-01],\n",
       "        [4.3095e-01, 3.3575e-02, 5.9006e-01],\n",
       "        [7.6603e-01, 3.9572e-02, 6.1763e-01],\n",
       "        [4.9847e-01, 8.9431e-01, 8.2992e-02],\n",
       "        [2.6753e-03, 2.2743e-01, 8.0808e-01],\n",
       "        [8.7802e-01, 8.6773e-01, 7.2834e-01],\n",
       "        [3.0641e-01, 3.1986e-01, 7.6927e-01],\n",
       "        [3.9682e-01, 1.6533e-02, 4.7571e-01],\n",
       "        [8.2539e-01, 5.1246e-01, 4.8047e-01],\n",
       "        [4.0002e-01, 6.2354e-01, 8.4343e-01],\n",
       "        [9.9192e-01, 3.8300e-01, 5.0407e-01],\n",
       "        [4.6552e-01, 1.3770e-02, 3.9362e-01],\n",
       "        [2.5608e-01, 3.9674e-01, 6.0047e-01],\n",
       "        [9.1359e-02, 3.9898e-01, 4.7742e-01],\n",
       "        [7.6157e-01, 2.3468e-01, 4.3210e-01],\n",
       "        [7.9960e-01, 1.8592e-01, 9.7125e-01],\n",
       "        [1.1043e-01, 8.2453e-01, 6.2138e-01],\n",
       "        [3.2298e-01, 8.3556e-01, 3.9616e-01],\n",
       "        [1.8385e-01, 6.9554e-01, 6.1647e-01],\n",
       "        [4.7902e-01, 3.7635e-01, 7.1778e-01],\n",
       "        [9.1104e-01, 9.0840e-01, 5.7602e-01],\n",
       "        [5.8648e-01, 7.4059e-01, 3.4267e-01],\n",
       "        [4.9256e-01, 9.9867e-01, 9.9500e-01],\n",
       "        [1.9539e-01, 7.7974e-02, 3.3439e-01],\n",
       "        [7.6138e-01, 6.4303e-01, 2.4554e-01],\n",
       "        [4.6537e-01, 8.4088e-01, 8.3200e-01],\n",
       "        [3.2565e-01, 9.6064e-01, 3.9217e-01],\n",
       "        [1.8727e-01, 9.9388e-02, 3.6361e-01],\n",
       "        [4.4178e-01, 8.9248e-01, 7.1813e-01],\n",
       "        [1.4312e-01, 3.1961e-01, 4.7173e-01],\n",
       "        [5.7947e-01, 7.5851e-01, 3.4147e-01],\n",
       "        [3.9614e-01, 7.3481e-01, 9.6407e-01],\n",
       "        [8.5048e-01, 6.9920e-01, 6.5920e-01],\n",
       "        [2.2850e-01, 5.8382e-01, 9.1463e-01],\n",
       "        [4.0143e-01, 8.7708e-01, 6.0543e-01],\n",
       "        [3.0890e-01, 9.5154e-01, 5.5678e-01],\n",
       "        [2.8803e-01, 2.8146e-01, 5.5072e-01],\n",
       "        [9.5330e-01, 1.3184e-01, 6.1481e-01],\n",
       "        [4.5741e-01, 7.3311e-01, 3.6112e-01],\n",
       "        [4.2499e-01, 4.5206e-01, 3.8661e-01],\n",
       "        [4.7414e-01, 8.3722e-01, 6.1785e-01],\n",
       "        [2.1561e-01, 5.2044e-01, 8.6818e-01],\n",
       "        [6.2154e-01, 7.6799e-01, 5.9951e-01],\n",
       "        [7.8819e-01, 3.7279e-01, 8.0705e-01],\n",
       "        [8.5186e-01, 4.2453e-01, 9.7906e-01],\n",
       "        [8.6428e-01, 1.9169e-01, 7.6882e-01],\n",
       "        [8.3982e-01, 2.6046e-01, 4.7418e-01],\n",
       "        [5.0141e-01, 9.0431e-01, 8.7501e-01],\n",
       "        [3.3108e-01, 2.4798e-01, 8.0798e-01],\n",
       "        [3.3713e-02, 1.5026e-01, 9.1323e-01],\n",
       "        [3.6051e-01, 5.8727e-01, 2.6566e-01],\n",
       "        [5.0594e-01, 6.0827e-01, 5.3726e-01],\n",
       "        [9.4186e-01, 5.4009e-01, 3.4638e-01],\n",
       "        [2.0511e-01, 5.4995e-01, 4.9179e-02],\n",
       "        [6.7165e-01, 3.2547e-01, 4.4791e-02],\n",
       "        [6.3103e-01, 7.3115e-01, 2.3523e-01],\n",
       "        [5.8669e-01, 2.5859e-01, 3.2518e-02],\n",
       "        [7.8135e-01, 4.7762e-01, 2.7033e-01],\n",
       "        [1.6034e-01, 7.1042e-01, 3.8389e-01],\n",
       "        [2.3050e-01, 7.7316e-01, 4.4048e-02],\n",
       "        [6.2569e-01, 5.1501e-01, 4.6862e-01],\n",
       "        [2.7639e-02, 5.9108e-01, 4.6618e-01],\n",
       "        [2.7159e-01, 7.5861e-02, 8.5459e-01],\n",
       "        [6.5149e-01, 6.4250e-01, 3.8419e-01],\n",
       "        [4.3696e-01, 5.5124e-01, 7.9641e-01],\n",
       "        [5.5398e-01, 1.3601e-01, 1.7339e-02],\n",
       "        [9.6619e-04, 6.9600e-01, 7.7445e-01],\n",
       "        [8.5945e-01, 7.7216e-02, 8.7368e-01],\n",
       "        [8.1164e-01, 2.9704e-01, 5.8546e-01],\n",
       "        [7.4119e-01, 5.4811e-01, 5.0472e-01],\n",
       "        [2.6843e-01, 5.9790e-01, 4.6986e-01],\n",
       "        [6.4701e-01, 2.1422e-01, 4.2319e-01],\n",
       "        [2.3010e-01, 4.2420e-01, 6.2202e-01],\n",
       "        [1.5179e-01, 7.7029e-01, 1.4277e-01],\n",
       "        [7.3222e-01, 3.0481e-01, 5.8586e-01],\n",
       "        [3.0940e-02, 7.0275e-01, 7.5804e-01],\n",
       "        [6.6239e-01, 8.2555e-01, 6.3903e-01],\n",
       "        [8.5449e-01, 4.5981e-01, 9.3268e-01],\n",
       "        [6.7392e-01, 6.4770e-01, 1.8799e-02],\n",
       "        [1.8840e-01, 6.4685e-01, 8.9126e-01],\n",
       "        [3.7416e-01, 7.6320e-01, 6.8866e-01],\n",
       "        [4.2421e-02, 4.6209e-01, 6.1963e-01],\n",
       "        [2.9084e-01, 8.9646e-02, 2.3283e-01],\n",
       "        [9.5627e-01, 9.0219e-01, 9.2514e-01],\n",
       "        [7.8552e-01, 1.6377e-01, 5.1433e-01],\n",
       "        [6.1481e-01, 5.1524e-01, 7.8347e-01],\n",
       "        [5.0338e-01, 9.0620e-01, 4.6741e-01],\n",
       "        [7.5270e-02, 2.3335e-01, 3.6526e-01],\n",
       "        [8.3387e-01, 4.1995e-02, 7.8687e-01],\n",
       "        [2.3482e-01, 9.1695e-01, 8.1811e-01],\n",
       "        [8.6294e-01, 9.9033e-01, 3.7675e-01],\n",
       "        [6.4550e-01, 1.5246e-01, 5.5818e-01],\n",
       "        [5.1911e-01, 1.0539e-01, 6.5715e-01],\n",
       "        [1.8920e-01, 6.0689e-01, 1.4846e-01],\n",
       "        [1.4787e-01, 4.5790e-01, 8.9964e-01],\n",
       "        [3.6232e-01, 7.2911e-03, 9.0630e-01],\n",
       "        [4.0319e-01, 1.9466e-01, 4.8111e-01],\n",
       "        [6.9633e-01, 8.1179e-01, 2.9150e-02],\n",
       "        [8.7279e-01, 8.6920e-01, 6.9830e-01],\n",
       "        [1.4107e-01, 4.3421e-01, 1.8222e-02],\n",
       "        [4.1611e-02, 6.1036e-01, 3.6501e-01],\n",
       "        [3.2595e-01, 3.8509e-01, 8.4154e-01],\n",
       "        [9.6765e-01, 9.6824e-01, 3.4640e-01],\n",
       "        [6.1565e-01, 8.9288e-01, 7.1897e-02],\n",
       "        [1.1888e-01, 6.7802e-01, 8.8339e-01],\n",
       "        [8.3081e-01, 1.1871e-01, 6.7889e-01],\n",
       "        [5.8569e-01, 4.6588e-01, 9.1251e-01],\n",
       "        [8.7203e-01, 8.9506e-03, 6.8732e-01],\n",
       "        [8.5087e-01, 5.7204e-02, 9.7982e-01],\n",
       "        [5.2836e-02, 8.3412e-01, 9.6343e-01],\n",
       "        [4.6797e-01, 8.8843e-01, 4.9243e-01],\n",
       "        [2.5401e-01, 4.7211e-01, 3.1509e-01],\n",
       "        [1.5009e-01, 4.2090e-01, 5.6034e-01],\n",
       "        [7.1205e-03, 2.3329e-01, 6.2528e-01],\n",
       "        [6.7909e-02, 2.2368e-01, 8.8395e-01],\n",
       "        [7.5272e-02, 5.9743e-02, 9.6538e-01],\n",
       "        [5.4633e-01, 8.8438e-01, 2.7070e-01],\n",
       "        [2.4662e-01, 1.8335e-01, 4.4258e-01],\n",
       "        [8.8185e-01, 4.8575e-02, 1.5364e-01],\n",
       "        [5.2191e-01, 8.7608e-01, 5.8455e-01],\n",
       "        [5.8994e-01, 6.5494e-02, 6.1130e-02],\n",
       "        [3.4029e-02, 9.3500e-01, 8.4724e-01],\n",
       "        [3.8832e-01, 4.9144e-01, 6.2212e-01],\n",
       "        [6.0667e-01, 2.3539e-02, 9.5287e-01],\n",
       "        [1.2546e-01, 6.5772e-01, 6.9623e-01],\n",
       "        [9.3053e-01, 7.1461e-01, 4.0689e-01],\n",
       "        [1.8825e-01, 4.3209e-01, 7.6516e-01],\n",
       "        [2.4156e-01, 5.7330e-01, 6.3054e-01],\n",
       "        [6.1795e-01, 1.5813e-02, 5.3982e-01],\n",
       "        [2.1744e-01, 6.3101e-01, 7.3742e-01],\n",
       "        [5.6963e-01, 8.4851e-01, 4.8033e-01],\n",
       "        [5.9180e-01, 4.8892e-01, 6.6696e-01],\n",
       "        [6.6771e-02, 3.3498e-01, 3.2481e-01],\n",
       "        [8.0875e-01, 9.5282e-01, 2.5824e-01],\n",
       "        [9.9950e-01, 4.4218e-01, 8.8780e-01],\n",
       "        [7.9232e-01, 9.1642e-01, 8.9030e-01],\n",
       "        [4.7113e-01, 9.3158e-01, 7.1832e-01],\n",
       "        [4.3198e-01, 6.9256e-01, 5.1459e-01],\n",
       "        [1.0675e-01, 5.1132e-01, 9.1299e-01],\n",
       "        [9.2681e-01, 7.5592e-02, 5.5847e-01],\n",
       "        [9.7917e-01, 5.1805e-01, 5.6555e-01],\n",
       "        [5.6795e-02, 5.9843e-02, 2.6943e-01],\n",
       "        [3.7796e-01, 3.8704e-01, 9.0655e-01],\n",
       "        [3.9561e-01, 9.1775e-01, 8.9822e-01],\n",
       "        [4.6766e-01, 5.5534e-01, 1.2385e-01],\n",
       "        [8.1785e-01, 6.2110e-01, 8.5452e-01],\n",
       "        [3.4320e-01, 1.0755e-01, 1.7320e-01],\n",
       "        [3.8779e-01, 6.6892e-01, 1.6348e-01],\n",
       "        [1.9144e-01, 1.5113e-01, 5.2867e-03],\n",
       "        [9.1493e-01, 4.8453e-01, 5.9088e-02],\n",
       "        [8.6497e-01, 1.6077e-01, 8.6482e-01],\n",
       "        [9.4577e-02, 9.2468e-02, 8.5852e-01],\n",
       "        [8.3969e-01, 6.1854e-01, 7.0578e-02],\n",
       "        [8.3930e-01, 3.6897e-01, 3.3381e-01],\n",
       "        [4.4020e-01, 6.1367e-01, 1.4379e-01],\n",
       "        [6.2471e-01, 5.8410e-01, 7.4836e-01],\n",
       "        [4.8362e-01, 8.7813e-01, 3.7691e-02],\n",
       "        [1.3925e-01, 2.7641e-01, 9.5707e-01],\n",
       "        [9.6631e-01, 3.2661e-01, 6.6254e-01],\n",
       "        [4.3119e-01, 8.5731e-01, 9.6286e-01],\n",
       "        [3.1492e-01, 2.5343e-01, 4.7879e-01],\n",
       "        [5.4106e-01, 9.0779e-01, 9.0727e-01],\n",
       "        [1.2661e-01, 9.6984e-01, 6.4603e-01],\n",
       "        [9.6958e-01, 2.0216e-01, 1.9287e-01],\n",
       "        [9.2876e-01, 1.4444e-01, 9.6881e-01],\n",
       "        [4.9565e-01, 1.8215e-01, 3.0168e-01],\n",
       "        [4.4136e-01, 2.8846e-01, 7.1815e-01],\n",
       "        [2.1886e-01, 7.4228e-02, 8.8640e-01],\n",
       "        [6.6394e-01, 3.3899e-02, 2.5809e-01],\n",
       "        [2.5035e-01, 8.0054e-01, 7.5321e-01],\n",
       "        [1.9531e-01, 5.4842e-04, 8.9210e-02],\n",
       "        [3.9081e-01, 2.1235e-01, 6.6105e-01],\n",
       "        [1.1899e-01, 7.5381e-02, 7.9034e-01],\n",
       "        [1.4267e-01, 4.4647e-01, 1.6458e-01],\n",
       "        [8.5485e-01, 9.4180e-01, 8.9961e-01]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_original[ 0, 0 :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`https://pytorch.org/docs/stable/generated/torch.permute.html` **for torch.permute**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000, 0.7210, 0.2043],\n",
       "         [0.7879, 0.6840, 0.8569],\n",
       "         [0.6919, 0.8551, 0.1637],\n",
       "         ...,\n",
       "         [0.1190, 0.0754, 0.7903],\n",
       "         [0.1427, 0.4465, 0.1646],\n",
       "         [0.8549, 0.9418, 0.8996]],\n",
       "\n",
       "        [[0.6502, 0.7327, 0.3314],\n",
       "         [0.8788, 0.4467, 0.0039],\n",
       "         [0.4634, 0.1263, 0.5258],\n",
       "         ...,\n",
       "         [0.1911, 0.5598, 0.1992],\n",
       "         [0.8329, 0.9450, 0.2317],\n",
       "         [0.9173, 0.6533, 0.7520]],\n",
       "\n",
       "        [[0.4954, 0.5092, 0.8199],\n",
       "         [0.5710, 0.1780, 0.0274],\n",
       "         [0.7527, 0.8100, 0.7292],\n",
       "         ...,\n",
       "         [0.6487, 0.7977, 0.3504],\n",
       "         [0.0925, 0.9707, 0.9956],\n",
       "         [0.0998, 0.5096, 0.0643]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.5405, 0.6423, 0.9145],\n",
       "         [0.4198, 0.0413, 0.5250],\n",
       "         [0.7430, 0.8136, 0.5015],\n",
       "         ...,\n",
       "         [0.7168, 0.0370, 0.9119],\n",
       "         [0.5443, 0.5318, 0.1368],\n",
       "         [0.0810, 0.5558, 0.3699]],\n",
       "\n",
       "        [[0.8906, 0.5276, 0.8182],\n",
       "         [0.1692, 0.2302, 0.5219],\n",
       "         [0.9778, 0.7806, 0.5658],\n",
       "         ...,\n",
       "         [0.7781, 0.2345, 0.9981],\n",
       "         [0.5121, 0.2311, 0.3031],\n",
       "         [0.7505, 0.5520, 0.3045]],\n",
       "\n",
       "        [[0.1997, 0.8399, 0.8719],\n",
       "         [0.8184, 0.3891, 0.1957],\n",
       "         [0.7298, 0.1124, 0.6494],\n",
       "         ...,\n",
       "         [0.0134, 0.3448, 0.6152],\n",
       "         [0.8460, 0.7787, 0.6070],\n",
       "         [0.8911, 0.3006, 0.3013]]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_original[0, 0, 0] = 1\n",
    "x_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.), tensor(1.))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_original[0, 0, 0] = 1\n",
    "x_original[0, 0, 0], x_permuted[0, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Indexing (selecting data from tensors)**\n",
    "\n",
    "indexing with Pytorch is very similar to Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a tensor\n",
    "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets index on our new tensor\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3]), tensor([1, 2, 3]))"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets index on the middle bracket\n",
    "x[0][0], x[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets index ont the most inner bracket(last bracket)\n",
    "x[0, 2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#you can also use \":\" to select \"all\" of a target dimension\n",
    "x[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 5, 8]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get all values of 0th and 1st dimension but only index 1 of 2nd dimension\n",
    "x[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get all values of the 0 dimension but only the 1 index value of the 1st and 2nd dimension\n",
    "x[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9)\n",
      "tensor(3)\n"
     ]
    }
   ],
   "source": [
    "print(x[0,2,2])\n",
    "print(x[0, 0,2 ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Pytorch Tensor & Numpy**\n",
    "\n",
    "`Numpy is a popular scientific Python numerical computing Library.`\n",
    "`And becouse of this, Pytorch has functionality to interact with it`\n",
    "\n",
    "* **Data in Numpy, want in Pytorch Tensor**-> `torch.from_numpy(ndarray)`\n",
    "* **Pytorch Tensor -> Numpy** -> `torch.Tesnor.numpy()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64),\n",
       " array([1., 2., 3., 4., 5., 6., 7.]))"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.arange(1.0, 8.0)\n",
    "tesnor = torch.from_numpy(array) # warning: when converting from numpy -> pytorch, pytorch reflects numpy's default datatype of 'float64' unless specified otherwise\n",
    "tesnor ,array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tesnor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tesnor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(1.0, 8.0).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 3., 4., 5., 6., 7., 8.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Change the value of array , what will this to do in tesnor?\n",
    "array = array + 1\n",
    "array, tesnor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tesnor to Numpy array\n",
    "tensor = torch.ones(7)\n",
    "\n",
    "numpy_tensor = tensor.numpy()\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2., 2., 2., 2., 2., 2., 2.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change the tesnor , what will happen to numpy_tensor?\n",
    "tensor = tensor + 1\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproducbility (trying to take random out of random)\n",
    "\n",
    "in short how a neural network learns:\n",
    "\n",
    "`start with random numbers -> tesnor operations -> update random number to try and make them better representation of the data -> agian -> again ->again...`\n",
    "\n",
    "**To reduce the randomness in neural network  and Pytorch comes the concept of a** **`random seed.`**\n",
    "\n",
    "Essentially what the random seed does is `\"flavour\"` the randomness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3716, 0.6546, 0.6110, 0.5990],\n",
      "        [0.5981, 0.2696, 0.2781, 0.1545],\n",
      "        [0.2127, 0.9911, 0.1848, 0.8769]])\n",
      "tensor([[0.6916, 0.5753, 0.8417, 0.6976],\n",
      "        [0.8682, 0.0127, 0.7293, 0.7531],\n",
      "        [0.9262, 0.1456, 0.1954, 0.3142]])\n",
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "#create tow random tensors \n",
    "\n",
    "random_tesnor_A = torch.rand(3,4)\n",
    "random_tensor_B = torch.rand(3,4)\n",
    "\n",
    "print(random_tesnor_A)\n",
    "print(random_tensor_B)\n",
    "\n",
    "print(random_tesnor_A == random_tensor_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4963, 0.7682, 0.0885, 0.1320],\n",
      "        [0.3074, 0.6341, 0.4901, 0.8964],\n",
      "        [0.4556, 0.6323, 0.3489, 0.4017]])\n",
      "tensor([[0.4963, 0.7682, 0.0885, 0.1320],\n",
      "        [0.3074, 0.6341, 0.4901, 0.8964],\n",
      "        [0.4556, 0.6323, 0.3489, 0.4017]])\n",
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "# lets`s make some random but reproducible tensors\n",
    "\n",
    "#set random seed\n",
    "RANDOM_SEED = 0\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_c = torch.rand(3,4)\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_d = torch.rand(3,4)\n",
    "\n",
    "print(random_tensor_c)\n",
    "print(random_tensor_d)\n",
    "print(random_tensor_c == random_tensor_d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Extra resources for Reproducibility`**\n",
    "\n",
    "*https://pytorch.org/docs/stable/generated/torch.manual_seed.html*\n",
    "\n",
    "*https://pytorch.org/docs/stable/notes/randomness.html*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Running tensor and Pytorch objects on the GPU's (and making fastre computations)**\n",
    "\n",
    "Gpus= faster computation on numbers becouse of cuda (paparallel)\n",
    "\n",
    " Getting a GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For pytorch since it's capable of running compute on the GPU or CPU, it's best practice to setup device agnostic code:\n",
    "\n",
    "https://pytorch.org/docs/stable/notes/cuda.html\n",
    "\n",
    "E.g Run on `GPU` if available, else defoult to `CPU`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Putting tesnor (and models) on the `GPU`\n",
    "\n",
    "The resons we want our tensor/model on the GPU becouse using a GPU results in faster computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) cpu\n"
     ]
    }
   ],
   "source": [
    "#create a tensor (default on the CPU)\n",
    "tesnor = torch.tensor([1,2,3])\n",
    "\n",
    "#tensor not on GpU\n",
    "print(tesnor,tesnor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move tesnor to GPU if available\n",
    "tensor_on_gpu = tesnor.to(device)\n",
    "tensor_on_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Moving tesnor to the CPU\n",
    "\n",
    "(some times when you need to run the model of `numpy` that dosnt work on gpu so you need to switch between GPU to CPU vice versa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if tesnor is on GPU, can't transform it to NumPy\n",
    "#tensor_on_gpu.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to fix the issue, we can first set it to the CPU\n",
    "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
    "tensor_back_on_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_on_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Building a pytorch Linear model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[159], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#create a linear layer model by subclassing nn.Module\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mLinearRegressionModelv2\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mmodule):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "#create a linear layer model by subclassing nn.Module\n",
    "class LinearRegressionModelv2(nn.module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # USe nn.linear() for creating the model parameters\n",
    "        self.linear_layer = nn.linear(in_features = 1, out_features = 1)\n",
    "\n",
    "    #def forward(self, x: torch.Tensor) -> torch.Tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
